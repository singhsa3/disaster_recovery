{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af27fd1c-f25c-4703-953d-7d13f84f2ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f7b2349-5070-4bc0-8775-49927e2b5cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sanje\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sanje\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sanje\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\sanje\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import sys\n",
    "# import libraries\n",
    "import pandas as pd\n",
    "import sqlalchemy as db\n",
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet'])\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3e9928f-deca-4aeb-b5c4-5202046efe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_data(database_filepath):\n",
    "    engine = db.create_engine('sqlite:///'+database_filepath)\n",
    "    df=pd.read_sql_query(\"SELECT * FROM tweets;\", engine)\n",
    "    X = df['message']\n",
    "    y = df.drop(['id','categories','message','original','genre'], axis=1)\n",
    "    y_cols= y.columns.tolist()\n",
    "    return X,y,y_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df7ef5f9-12f2-443a-9f58-bbefb4046a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>categories</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>related-1;request-0;offer-0;aid_related-0;medi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>related-1;request-0;offer-0;aid_related-1;medi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Looking for someone but no name</td>\n",
       "      <td>Patnm, di Maryani relem pou li banm nouvel li ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>related-1;request-0;offer-0;aid_related-0;medi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>direct</td>\n",
       "      <td>related-1;request-1;offer-0;aid_related-1;medi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>says: west side of Haiti, rest of the country ...</td>\n",
       "      <td>facade ouest d Haiti et le reste du pays aujou...</td>\n",
       "      <td>direct</td>\n",
       "      <td>related-1;request-0;offer-0;aid_related-0;medi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "2   8                    Looking for someone but no name   \n",
       "3   9  UN reports Leogane 80-90 destroyed. Only Hospi...   \n",
       "4  12  says: west side of Haiti, rest of the country ...   \n",
       "\n",
       "                                            original   genre  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct   \n",
       "2  Patnm, di Maryani relem pou li banm nouvel li ...  direct   \n",
       "3  UN reports Leogane 80-90 destroyed. Only Hospi...  direct   \n",
       "4  facade ouest d Haiti et le reste du pays aujou...  direct   \n",
       "\n",
       "                                          categories  related  request  offer  \\\n",
       "0  related-1;request-0;offer-0;aid_related-0;medi...        1        0      0   \n",
       "1  related-1;request-0;offer-0;aid_related-1;medi...        1        0      0   \n",
       "2  related-1;request-0;offer-0;aid_related-0;medi...        1        0      0   \n",
       "3  related-1;request-1;offer-0;aid_related-1;medi...        1        1      0   \n",
       "4  related-1;request-0;offer-0;aid_related-0;medi...        1        0      0   \n",
       "\n",
       "   aid_related  medical_help  ...  aid_centers  other_infrastructure  \\\n",
       "0            0             0  ...            0                     0   \n",
       "1            1             0  ...            0                     0   \n",
       "2            0             0  ...            0                     0   \n",
       "3            1             0  ...            0                     0   \n",
       "4            0             0  ...            0                     0   \n",
       "\n",
       "   weather_related  floods  storm  fire  earthquake  cold  other_weather  \\\n",
       "0                0       0      0     0           0     0              0   \n",
       "1                1       0      1     0           0     0              0   \n",
       "2                0       0      0     0           0     0              0   \n",
       "3                0       0      0     0           0     0              0   \n",
       "4                0       0      0     0           0     0              0   \n",
       "\n",
       "   direct_report  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = db.create_engine('sqlite:///'+'../data/DisasterResponse.db')\n",
    "df=pd.read_sql_query(\"SELECT * FROM tweets;\", engine)\n",
    "X = df['message']\n",
    "y = df.drop(['id','categories','message','original','genre'], axis=1)\n",
    "y_cols= y.columns.tolist()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5baa3663-41bf-4f2d-b028-09fc895ad46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def tokenize(example_sent):\n",
    "    example_sent = example_sent.lower()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(example_sent)\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    filtered_Lemm_sentence = [wordnet_lemmatizer.lemmatize(w).strip() for w in filtered_sentence]\n",
    "    return filtered_Lemm_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0f0ee3d-e04f-4f8d-92b3-bd10d0bdd8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def build_model():\n",
    "    RndmFrst_pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier(),n_jobs=20))\n",
    "    ])    \n",
    "    return RndmFrst_pipeline\n",
    "       \n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, category_names):\n",
    "    prediction = model.predict(X_test)\n",
    "    for i, cat in enumerate(category_names):\n",
    "        print(i, cat)\n",
    "        print('------')\n",
    "        print(classification_report(y_true= y_test[cat].values.reshape(-1,1), y_pred=prediction[:,i].reshape(-1,1)))\n",
    "        print('------')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "843f7cb4-7396-453f-9335-9c110cba6a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def save_model(model, model_filepath):\n",
    "    filehandler = open(model_filepath,\"wb\")\n",
    "    pickle.dump(model,filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b89e6cc5-9c07-456e-adce-af8a573600eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def main():\n",
    "    try:\n",
    "        if len(sys.argv) == 3:\n",
    "            database_filepath, model_filepath = sys.argv[1:]\n",
    "            print('Loading data...\\n    DATABASE: {}'.format(database_filepath))\n",
    "            X, Y, category_names = load_data(database_filepath)\n",
    "            X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "            print('Building model...')\n",
    "            model = build_model()\n",
    "\n",
    "            print('Training model...')\n",
    "            model.fit(X_train, Y_train)\n",
    "\n",
    "            print('Evaluating model...')\n",
    "            evaluate_model(model, X_test, Y_test, category_names)\n",
    "\n",
    "            print('Saving model...\\n    MODEL: {}'.format(model_filepath))\n",
    "            save_model(model, model_filepath)\n",
    "\n",
    "            print('Trained model saved!')\n",
    "\n",
    "        else:\n",
    "            print('Please provide the filepath of the disaster messages database '\\\n",
    "                  'as the first argument and the filepath of the pickle file to '\\\n",
    "                  'save the model to as the second argument. \\n\\nExample: python '\\\n",
    "                  'train_classifier.py ../data/DisasterResponse.db classifier.pkl')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f863a52-b095-451f-8c9c-3811f6f156a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "    DATABASE: -f\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217a414e-726b-4dce-b523-26eb6e5db8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
